{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89B27-TGiDNB"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U6rgexPXmY37",
    "outputId": "62a48076-f690-4635-e9ca-14871c27db88"
   },
   "outputs": [],
   "source": [
    "import os, sys, math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9S3uKC_iXY5"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8K6hL_kiWve"
   },
   "outputs": [],
   "source": [
    "GCS_PATTERN = 'dataset/train/*/*.png'\n",
    "GCS_OUTPUT = 'dataset/tfrecords/train'  # prefix for output file names\n",
    "SHARDS = 16\n",
    "TARGET_SIZE = [512, 512]\n",
    "CLASSES = [b'negative', b'positive',] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MPkvHdAYNt9J"
   },
   "outputs": [],
   "source": [
    "#@title \"display utilities [RUN ME]\"\n",
    "def display_9_images_from_dataset(dataset):\n",
    "  plt.figure(figsize=(13,13))\n",
    "  subplot=331\n",
    "  for i, (image, label) in enumerate(dataset):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.numpy().astype(np.uint8))\n",
    "    plt.title(label.numpy().decode(\"utf-8\"), fontsize=16)\n",
    "    subplot += 1\n",
    "    if i==8:\n",
    "      break\n",
    "  #plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvPXiovhi3ZZ"
   },
   "source": [
    "## Read images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nwsZ8X59mu24",
    "outputId": "df9500bf-296b-4807-9b7f-f0b0be4fa928"
   },
   "outputs": [],
   "source": [
    "nb_images = len(tf.io.gfile.glob(GCS_PATTERN))\n",
    "shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
    "print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))\n",
    "\n",
    "def decode_jpeg_and_label(filename):\n",
    "  bits = tf.io.read_file(filename)\n",
    "  image = tf.image.decode_png(bits)\n",
    "  # parse flower name from containing directory\n",
    "  label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n",
    "  label = label.values[-2]\n",
    "  return image, label\n",
    "\n",
    "filenames = tf.data.Dataset.list_files(GCS_PATTERN, seed=35155) # This also shuffles the images\n",
    "dataset1 = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "id": "nrRTvVzEOfMl",
    "outputId": "ec596e8a-fbfa-4e4f-e639-176463f30bdc"
   },
   "outputs": [],
   "source": [
    "display_9_images_from_dataset(dataset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDIfPMGCjqLO"
   },
   "source": [
    "## Write dataset to TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_image(image, label): \n",
    "    height = tf.shape(image)[0] \n",
    "    width = tf.shape(image)[1] \n",
    "    image = tf.cast(image, tf.uint8) \n",
    "    image = tf.image.encode_png(image) \n",
    "    return image, label, height, width\n",
    "\n",
    "dataset = dataset1.map(unpack_image, num_parallel_calls=AUTO)\n",
    "dataset = dataset.batch(shard_size) # sharding: there will be one \"batch\" of images per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "9X82-4D2syG4",
    "outputId": "0f44ff1e-6e42-48bd-c77b-703151805ece"
   },
   "outputs": [],
   "source": [
    "# Three types of data can be stored in TFRecords: bytestrings, integers and floats\n",
    "# They are always stored as lists, a single data element will be a list of size 1\n",
    "\n",
    "def _bytestring_feature(list_of_bytestrings):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
    "\n",
    "def _int_feature(list_of_ints): # int64\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "\n",
    "def _float_feature(list_of_floats): # float32\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
    "  \n",
    "\n",
    "def to_tfrecord(tfrec_filewriter, img_bytes, label, height, width):  \n",
    "  class_num = np.argmax(np.array(CLASSES)==label) \n",
    "  one_hot_class = np.eye(len(CLASSES))[class_num]    \n",
    "\n",
    "  feature = {\n",
    "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
    "      \"class\": _int_feature([class_num]),        # one class in the list\n",
    "      \n",
    "      # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
    "      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
    "      \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n",
    "      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n",
    "  }\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  \n",
    "print(\"Writing TFRecords\")\n",
    "for shard, (image, label, height, width) in enumerate(dataset):\n",
    "  # batch size used as shard size here\n",
    "  shard_size = image.numpy().shape[0]\n",
    "  # good practice to have the number of records in the filename\n",
    "  filename = GCS_OUTPUT + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
    "  \n",
    "  with tf.io.TFRecordWriter(filename) as out_file:\n",
    "    for i in range(shard_size):\n",
    "      example = to_tfrecord(out_file,\n",
    "                            image.numpy()[i], # re-compressed image: already a byte string\n",
    "                            label.numpy()[i],\n",
    "                            height.numpy()[i],\n",
    "                            width.numpy()[i])\n",
    "      out_file.write(example.SerializeToString())\n",
    "    print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHG5TzULkJh1"
   },
   "source": [
    "## Read  from TFRecord Dataset\n",
    "**Resume running the cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjw8GURL8wjk"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
    "        \n",
    "        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
    "        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
    "        \"size\":          tf.io.FixedLenFeature([2], tf.int64),  # two integers\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)        # a certain number of floats\n",
    "    }\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    # FixedLenFeature fields are now ready to use: exmple['size']\n",
    "    # VarLenFeature fields require additional sparse_to_dense decoding\n",
    "    \n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
    "#     image = tf.reshape(image, [*TARGET_SIZE, 3])\n",
    "    \n",
    "    class_num = example['class']\n",
    "    \n",
    "    label  = example['label']\n",
    "    height = example['size'][0]\n",
    "    width  = example['size'][1]\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    return image, class_num, label, height, width, one_hot_class\n",
    "    \n",
    "# read from TFRecords. For optimal performance, read from multiple\n",
    "# TFRecord files at once and set the option experimental_deterministic = False\n",
    "# to allow order-altering optimizations.\n",
    "\n",
    "option_no_order = tf.data.Options()\n",
    "option_no_order.experimental_deterministic = False\n",
    "\n",
    "filenames = tf.io.gfile.glob(GCS_OUTPUT + \"*.tfrec\")\n",
    "dataset4 = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "dataset4 = dataset4.with_options(option_no_order)\n",
    "dataset4 = dataset4.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "dataset4 = dataset4.shuffle(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "colab_type": "code",
    "id": "crKBTwVXLBWm",
    "outputId": "4a82b248-9f2b-4880-ff0d-eb66641096fb"
   },
   "outputs": [],
   "source": [
    "display_dataset = dataset4.map(lambda image, class_num, label, height, width, one_hot_class: (image, label))\n",
    "display_9_images_from_dataset(display_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flower pictures to TFRecords.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf22-cpu.2-2.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf22-cpu.2-2:m47"
  },
  "kernelspec": {
   "display_name": "Python [conda env:cancer]",
   "language": "python",
   "name": "conda-env-cancer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
